<?xml version="1.0" encoding="UTF-8"?>
<dds xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://community.rti.com/schema/7.3.0/rti_dds_qos_profiles.xsd" version="7.3.0">
    <qos_library name="DPLibrary">

      <qos_profile name="DefaultParticipant" base_name="BuiltinQosLib::Generic.Common">

        <!-- 
          USE CASE: Baseline Domain Participant QoS to be used system wide and 
          extended for specific use cases. 
        -->


        <domain_participant_qos>
          <!-- Discovery-related optimizations -->
          <base_name>
            <element>BuiltinQosSnippetLib::Optimization.Discovery.Common</element>
            <element>BuiltinQosSnippetLib::Optimization.Discovery.Endpoint.Fast</element>
            <element>BuiltinQosSnippetLib::Optimization.ReliabilityProtocol.Common</element>
          </base_name>
          <transport_builtin>
            <shmem>
              <!-- message_size_max should be >= largest message over SHMEM -->
              <!-- receive_buffer_size and received_message_count_max should be modified accordingly -->
              <!-- As a general rule: receive_buffer_size = message_size_max * received_message_count_max -->

              <!-- <message_size_max>262144</message_size_max>
              <receive_buffer_size>8388608</receive_buffer_size>
              <received_message_count_max>32</received_message_count_max> -->
            </shmem>
            <udpv4>
              <message_size_max>65530</message_size_max>
              <!-- These settings help when throughput is high. -->
              <!-- You need to manually modify these in your kernel. -->
              <!-- You should add the sysctl commands to your startup script. -->
              <!--    Linux: https://community.rti.com/howto/improve-rti-connext-dds-network-performance-linux -->
              <!--    QNX: https://community.rti.com/kb/how-increase-socket-buffer-sizes-qnx -->
              <!--    Windows: no need to do anything at the OS level -->
              <send_socket_buffer_size>10485760</send_socket_buffer_size>
              <recv_socket_buffer_size>10485760</recv_socket_buffer_size>
              <!-- You should set the ALLOW_INTERFACES_LIST environment variable
                  to the IP address you'd like to use. This helps avoid potential
                  duplicate traffic because Connext will use all the available
                  interfaces to receive data, causing remote DPs to send the same
                  data to multiple destinations. -->
              <!-- This is commented out for easier out-of-the-box behavior -->
              <!-- <allow_interfaces_list>
                <element>$(ALLOW_INTERFACES_LIST)</element>
              </allow_interfaces_list> -->
            </udpv4>
          </transport_builtin>
        </domain_participant_qos>
      </qos_profile>


      <qos_profile name="LargeDataParticipant" base_name="DefaultParticipant">

        <!-- 
          USE CASE: 
          Participant that is used to transfer "Large" messages i.e. 
          larger than default 65kB and where resource impact would be considerable 
          if applied system wide. 

          This is intended to be used in tandem with a LargeDataQoS set at the Topic level  
          so the application can use either UDP or SHMEM, but the LargeData Topic selects  
          only SHMEM so it has access to the larger message_size_max.
        -->

        <domain_participant_qos>
          <transport_builtin>
            <mask>SHMEM|UDPv4</mask>
            <shmem>
              <!--  
                Increase the message size that is sent to minimize re-assembly/latency impact 
                Set to >= largest message size to minimize fragementation of large messages
                This use case is where each image size is fairly consistent.
                Example: 3 MB
              
              -->
              <message_size_max>3145728</message_size_max>

              <!-- 
                This is for the use case where we only care about the last few image frames
              -->
              <received_message_count_max>3</received_message_count_max>

              <!-- 
              
                Increase the receive buffer size specific to the SHMEM transport 
                This should be equal to message_size_max * received_message_count_max
                This example the message_size_max is ~= avg message size.
              -->
              <receive_buffer_size>9437184</receive_buffer_size>
            </shmem>
          </transport_builtin>
        </domain_participant_qos>
      </qos_profile>

    </qos_library>


    <qos_library name="DataPatternsLibrary">

    <qos_profile name="EventQoS" base_name="BuiltinQosLib::Generic.Common">
      <!-- 
        
        USE CASE: 
        Even Topics such as button pushes or alerts. When events are triggered,
        the system should almost always do something, meaning that you
        don't want the system to lose the event. This means that the system
        requires strictly reliable communication. 

        Since events and alerts are critical and non-periodic data, it is
        important to detect situations in which communication between a
        DataWriter and DataReader is broken. 

        This use case also alignes with Aperiodic data i.e. messages are only 
        sent out aperiodically.
        This is why this QoS Profile sets the
        LivelinessQosPolicy. If the DataWriter does not assert its
        liveliness in a timely manner, the DataReader will report loss
        of liveliness to the application.
        -->

      <!-- Having snippets here makes it easier to understand what QoS is applied -->
      <base_name>
        <element>BuiltinQosSnippetLib::QosPolicy.Reliability.Reliable</element>
        <element>BuiltinQosSnippetLib::QosPolicy.History.KeepAll</element>
        <element>BuiltinQosSnippetLib::Optimization.ReliabilityProtocol.KeepAll</element>
      </base_name>

      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <publication_name>
          <name>EventWriter</name>
        </publication_name>

        <!-- 
        Liveliness QoS automatically sends out a "heartbeat" message and triggers 
        the on_liveliness_changed callback if missed 
        -->
        <liveliness>
          <lease_duration>
            <sec>4</sec>
            <nanosec>0</nanosec>
          </lease_duration>
        </liveliness>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "subscription name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>EventReader</name>
        </subscription_name>

        <!-- 
        Liveliness QoS automatically sends out a "heartbeat" message and triggers 
        the on_liveliness_changed callback if missed 
        -->
        <liveliness>
          <lease_duration>
            <sec>10</sec>
            <nanosec>0</nanosec>
          </lease_duration>
        </liveliness>

      </datareader_qos>

    </qos_profile>

    <qos_profile name="CommandStrength10QoS" base_name="DataPatternsLibrary::EventQoS">
      <!-- 
        USE CASE:
        Mutli command arbitration where different commands have differnt "strengths" 
        to override as necessary.

        Example: Auto -> Obstacle Override -> Manual Override

        This inherits from the EventQoS to use it's baseline.
        -->

      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <publication_name>
          <name>CommandStrength10QoSWriter</name>
        </publication_name>

        <!-- This means only the reader will only accept samples from the strongest writer -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

        <ownership_strength>
          <value>10</value>
        </ownership_strength>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "subscription name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>CommandStrength10QoSReader</name>
        </subscription_name>

        <!-- On the reader side just need to set to "Exclusive" -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

      </datareader_qos>

    </qos_profile>

    <qos_profile name="CommandStrength20QoS" base_name="DataPatternsLibrary::EventQoS">
      <!-- 
        USE CASE:
        Mutli command arbitration where different commands have differnt "strengths" 
        to override as necessary.

        Example: Auto -> Obstacle Override -> Manual Override


        This inherits from the EventQoS to use it's baseline.
        -->


      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <publication_name>
          <name>CommandStrength20QoSWriter</name>
        </publication_name>

        <!-- This means only the reader will only accept samples from the strongest writer -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

        <ownership_strength>
          <value>20</value>
        </ownership_strength>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "subscription name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>CommandStrength20QoSReader</name>
        </subscription_name>

        <!-- On the reader side just need to set to "Exclusive" -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

      </datareader_qos>

    </qos_profile>

    <qos_profile name="CommandStrength30QoS" base_name="DataPatternsLibrary::EventQoS">
      <!-- 
        USE CASE:
        Mutli command arbitration where different commands have differnt "strengths" 
        to override as necessary.

        Example: Auto -> Obstacle Override -> Manual Override

        This inherits from the EventQoS to use it's baseline.
        -->


      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <publication_name>
          <name>CommandStrength30QoSWriter</name>
        </publication_name>

        <!-- This means only the reader will only accept samples from the strongest writer -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

        <ownership_strength>
          <value>30</value>
        </ownership_strength>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "subscription name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>CommandStrength30QoSReader</name>
        </subscription_name>

        <!-- On the reader side just need to set to "Exclusive" -->
        <ownership>
          <kind>EXCLUSIVE_OWNERSHIP_QOS</kind>
        </ownership>

      </datareader_qos>

    </qos_profile>


    <qos_profile name="MetadataQoS" base_name="BuiltinQosLib::Generic.Common">

      <!-- 
        USE CASE:
        DataWriter will keep in its queue the last value that was published for 
        each sample instance. Late-joining DataReaders will get that value when 
        they join the system. 
        -->

      <!-- Having snippets here makes it easier to understand what QoS is applied -->
      <base_name>
        <element>BuiltinQosSnippetLib::QosPolicy.Reliability.Reliable</element>
        <element>BuiltinQosSnippetLib::QosPolicy.History.KeepLast_1</element>
        <element>BuiltinQosSnippetLib::Optimization.ReliabilityProtocol.KeepLast</element>
        <element>BuiltinQosSnippetLib::QosPolicy.Durability.TransientLocal</element>
      </base_name>

      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->        
        <publication_name>
          <name>MetaDataWriter</name>
        </publication_name>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>MetaDataReader</name>
        </subscription_name>

      </datareader_qos>
    </qos_profile>

    <qos_profile name="StatusQoS" base_name="BuiltinQosLib::Generic.Common">

      <!-- 
        USE CASE:
        Applications that expect periodic data such as sensor/positional data etc. 
        There is no reliability mechanism applied as data loss is permitted.
        The deadline that is set in this QoS Profile can be used to detect when 
        DataWriters are not publishing data with the expected periodicity.
        -->


      <!-- Having snippets here makes it easier to understand what QoS is applied -->
      <base_name>
        <element>BuiltinQosSnippetLib::QosPolicy.Reliability.BestEffort</element>
        <element>BuiltinQosSnippetLib::QosPolicy.History.KeepLast_1</element>
      </base_name>


      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <publication_name>
          <name>StatusWriter</name>
        </publication_name>

        <!-- 
        Deadline QoS triggers on_requested_deadline_missed if the periodic writer  
        doesn't send out samples within the expected timeframe/expected rate
        Can trigger failover scenarios etc. 
        -->
        <deadline> 
          <period>
            <sec>4</sec>
            <nanosec>0</nanosec>
          </period>
        </deadline>

      </datawriter_qos>

      <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
        <subscription_name>
          <name>StatusReader</name>
        </subscription_name>


        <!-- 
        Deadline QoS triggers on_requested_deadline_missed if the periodic writer  
        doesn't send out samples within the expected timeframe/expected rate
        Can trigger failover scenarios etc. 
        -->
        <deadline>
          <period>
            <sec>10</sec>
            <nanosec>0</nanosec>
          </period>
        </deadline>

      </datareader_qos>

    </qos_profile>

    <qos_profile name="LargeDataSHMEMQoS" base_name="BuiltinQosLib::Generic.Common">


      <!-- 
      USE CASE:
      Large Data being sent over SHMEM with lowest latency required i.e. no RELIABILITY> 
      -->


      <base_name>
        <element>BuiltinQosSnippetLib::QosPolicy.Reliability.BestEffort</element>
        <element>BuiltinQosSnippetLib::QosPolicy.History.KeepLast_1</element>
      </base_name>

      <datawriter_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
          <publication_name>
            <name>LargeDataSHMEMWriter</name>
          </publication_name>

        <!-- 
          This makes the writers/readers on this topic use the "larger" SHMEM message_size_max.
          By Default Connext uses the smallest transports message_size_max i.e. UDP 
          -->
          <transport_selection>
            <enabled_transports>
              <element>shmem</element>
            </enabled_transports>
          </transport_selection>

        <!-- 
            The default is normally 23 samples.
            This just allocates less memory up front for very large samples 
          -->
          <resource_limits>
            <initial_samples>2</initial_samples>
          </resource_limits>

        </datawriter_qos>

        <datareader_qos>

        <!-- 
          In Admin Console can look under QoS tab for "publication name" to 
          see which QoS Profile is being used
          -->
          <subscription_name>
            <name>LargeDataReader</name>
          </subscription_name>

          <transport_selection>
            <enabled_transports>
              <element>shmem</element>
            </enabled_transports>
          </transport_selection>

        <resource_limits>
          <initial_samples>2</initial_samples>
        </resource_limits>
 
      </datareader_qos>
    </qos_profile>


    <qos_profile name="LargeDataSHMEM_ZCQoS" base_name="LargeDataSHMEMQoS">

      <!-- 
      USE CASE:
      Large Data using SHMEM with Zero-Copy Transfer Mode
      Inherits from LargeDataSHMEMQoS and adds QoS for ZC impact
      
      KEY FEATURES:
      - Zero-copy transfers within the same host (true zero-copy in shared memory)
      - No serialization overhead between hosts (requires same endianness)
      - Optimized for FlatData with direct memory access
      - Application Acknowledgement to prevent data inconsistencies between reader and writer due to direct memory access.
      -->

      <!-- Increase the RELIABILITY traffic rate to ensure minimal latency -->
      <base_name>
        <element>BuiltinQosSnippetLib::Optimization.ReliabilityProtocol.HighRate</element>
      </base_name>

      <datawriter_qos>

        <publication_name>
          <name>LargeDataSHMEM_ZCWriter</name>
        </publication_name>

        <reliability>
          <!-- 
            Set to RELIABLE and Application Level Acknowledgement so we can 
            feedback sequence numbers fully processed by reader to writer 
          -->
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <acknowledgment_kind>APPLICATION_AUTO_ACKNOWLEDGMENT_MODE</acknowledgment_kind>
        </reliability>


          

      </datawriter_qos>

      <datareader_qos>

        <subscription_name>
          <name>LargeDataSHMEM_ZCQoSReader</name>
        </subscription_name>

        <reliability>
          <!-- 
            Set to RELIABLE and Application Level Acknowledgement so we can 
            feedback sequence numbers fully processed by reader to writer 
          -->
          <kind>RELIABLE_RELIABILITY_QOS</kind>
          <acknowledgment_kind>APPLICATION_AUTO_ACKNOWLEDGMENT_MODE</acknowledgment_kind>
        </reliability>

      </datareader_qos>

    </qos_profile>


    <qos_profile name="AssignerQoS">

      <!-- 
        Use this profile to change QoS Profile assignments without re-compiling
        All DataWriters/DataReaders get set to this profile and we centralize assignment 
        Overrides in order of assignment
        -->

      <datawriter_qos topic_filter="LargeData*" base_name="LargeDataSHMEMQoS" />
      <datareader_qos topic_filter="LargeData*" base_name="LargeDataSHMEMQoS" />

      <datawriter_qos topic_filter="Position*" base_name="StatusQoS" />
      <datareader_qos topic_filter="Position*" base_name="StatusQoS" />

      <datawriter_qos topic_filter="Config*" base_name="MetadataQoS" />
      <datareader_qos topic_filter="Config*" base_name="MetadataQoS" />

      <datawriter_qos topic_filter="Button*" base_name="EventQoS" />
      <datareader_qos topic_filter="Button*" base_name="EventQoS" />

      <datawriter_qos topic_filter="Command*" base_name="EventQoS" />
      <datareader_qos topic_filter="Command*" base_name="EventQoS" />

    </qos_profile>
  </qos_library>

</dds>
